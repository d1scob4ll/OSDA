{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fa9cab-543d-4a09-9b58-b28d38d3f9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fcalc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5885b8cd-c6a1-4a15-acdf-847aa3046573",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DATAFRAME CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677bbc59-e7cc-4e75-83ac-378c2b4e6154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = ['No  System  mount  price  con  snow  ice  dur  Accegrade',\n",
    " '1 SK F 206 1.9 1.4 1.8  2.7 F',\n",
    " '2 SRK For R  520  2.1 0.8 3.8  2.3 F',\n",
    " '3 SK F 160  1.7 1.9 1.6  3.7 F',\n",
    " '4 SK F 213  1.7 2.0  2.4  3.4 F',\n",
    " '5 SMS For R  598 1.6 2.4 7  28 F',\n",
    " '6 SK F 109  2.0 19  2.4  3.7 F',\n",
    " '7 SRK For R  325  2.0 2.1 3.2  2.8 F',\n",
    " '8 SMS For R  498 1.5 3.3 3.5  2.0 T',\n",
    " '9 SRK For R  396  2.8 2.1 3.1  2.5 T',\n",
    " '10 SRK For R  325  2.2 2.2  4.6  3.2 T',\n",
    " '11 SRK For R  389  2.0 2.2 3.3  4.3 T',\n",
    " '12 SRK F 298  2.5 2.3 3.3  2.8 T',\n",
    " '13 SK F 149 1.9 2.5 4.0  3.8 T',\n",
    " '14 SMS For R  684  17 3.3 44  2.2 T',\n",
    " '15 SK F 99 2.8 2.2  2.5  4.0 T',\n",
    " '16 SK F 140  2.6 2.3 3.3  3.4 T',\n",
    " '17 SK F 215  2.3 3.8  48  2.3 T']\n",
    "\n",
    "lines2 = ['No System mount price con snow ice dur Accegrade',\n",
    "'1 SK F 149 1.9 2.5 4.0 3.8 T',\n",
    "'2 SRK For R 520 2.1 0.8 3.8 2.3 F',\n",
    "'3 SRK For R 389 2.0 2.2 3.3 4.3 T',\n",
    "'4 SK F 213 1.7 2.0 2.4 3.4 F',\n",
    "'5 SMS For R 598 1.6 2.4 7 2.8 F',\n",
    "'6 SK F 109 2.0 1.9 2.4 3.7 F',\n",
    "'7 SRK For R 325 2.0 2.1 3.2 2.8 F',\n",
    "'8 SMS For R 498 1.5 3.3 3.5 2.0 T',\n",
    "'9 SRK For R 396 2.8 2.1 3.1 2.5 T',\n",
    "'10 SK F 160 1.7 1.9 1.6 3.7 F',\n",
    "'11 SRK For R 389 2.0 2.2 3.3 4.3 T',\n",
    "'12 SRK F 298 2.5 2.3 3.3 2.8 T',\n",
    "'13 SK F 206 1.9 1.4 1.8 2.7 F',\n",
    "'14 SMS For R 684 1.7 3.3 4.4 2.2 T',\n",
    "'15 SK F 99 2.8 2.2 2.5 4.0 T',\n",
    "'16 SK F 140 2.6 2.3 3.3 3.4 T',\n",
    "'17 SK F 215 2.3 3.8 4.8 2.3 T']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de7f0ad-13a4-41f1-a41c-cebc23b37e20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataframe_const(lines):\n",
    "    data_rows = []\n",
    "\n",
    "    for line in lines[1:]:  \n",
    "        row_elements = line.split()\n",
    "        corrected_elements = []\n",
    "        i = 0\n",
    "        while i < len(row_elements):\n",
    "            if row_elements[i] == 'For' and i+1 < len(row_elements) and row_elements[i+1] == 'R':\n",
    "                corrected_elements.append('F or R')\n",
    "                i += 2  \n",
    "            else:\n",
    "                corrected_elements.append(row_elements[i])\n",
    "                i += 1\n",
    "        data_rows.append(corrected_elements)\n",
    "        \n",
    "    df = pd.DataFrame(columns=[\"No\", \"System\", \"mount\", \"price\", \"con\", \"snow\", \"ice\", \"dur\", \"Accgrade\"])\n",
    "\n",
    "    for index, row in enumerate(data_rows):\n",
    "        corrected_row = {}\n",
    "\n",
    "        corrected_row[\"No\"] = row[0]\n",
    "        corrected_row[\"System\"] = row[1]\n",
    "        corrected_row[\"mount\"] = row[2] if row[2] in ['F', 'F or R'] else 'F'\n",
    "        corrected_row[\"price\"] = row[3] if row[2] in ['F', 'F or R'] else row[2]\n",
    "        corrected_row[\"con\"] = row[4] if row[2] in ['F', 'F or R'] else row[3]\n",
    "        corrected_row[\"snow\"] = row[5] if row[2] in ['F', 'F or R'] else row[4]\n",
    "        corrected_row[\"ice\"] = row[6] if row[2] in ['F', 'F or R'] else row[5]\n",
    "        corrected_row[\"dur\"] = row[7] if row[2] in ['F', 'F or R'] else row[6]\n",
    "        corrected_row[\"Accgrade\"] = row[-1]\n",
    "\n",
    "        df = df.append(corrected_row, ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af393646-72c8-43e0-a46b-d002f1f5c80a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = dataframe_const(lines)\n",
    "df2 = dataframe_const(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02f3ed7-805b-4aaf-bfc7-26cfe40c9b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop('No', axis=1)\n",
    "df2 = df2.drop('No', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3306c7e4-fee9-4c81-ab3b-982b82c61aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = ['price', 'con', 'snow', 'ice', 'dur']\n",
    "df[num] = df[num].apply(pd.to_numeric)\n",
    "df2[num] = df2[num].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be99a2f9-a791-4f66-8b21-07732cc0ed4c",
   "metadata": {},
   "source": [
    "## PROCESSING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69bcc6b9-fa69-4d65-b481-1d5e7d67ae38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    tr_rows = [i for i in range(0, 14)]\n",
    "    te_rows = [14, 15, 16]\n",
    "    train = df.iloc[tr_rows]\n",
    "    test = df.iloc[te_rows]\n",
    "    \n",
    "    y_train = train['Accgrade'] == 'T'\n",
    "    y_test = test['Accgrade'] == 'T'\n",
    "    X_train = train.drop('Accgrade', axis=1)\n",
    "    X_test = test.drop('Accgrade', axis=1)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dabbee9a-8d9b-47a3-982a-2a87d9c8f4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def est(df):\n",
    "    X_train, y_train, X_test, y_test = split(df)\n",
    "    pat_cls = fcalc.classifier.PatternBinaryClassifier(X_train.values, y_train.to_numpy(), \n",
    "                                                       categorical=np.array([0, 1]), method = \"standard-support\")\n",
    "    pat_cls.predict(X_test.values)\n",
    "    acc = round(accuracy_score(y_test, pat_cls.predictions),4)\n",
    "    \n",
    "    print(\"accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc4dcd6-7585-466c-92bc-950a30cbb6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.0\n",
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "est(df)\n",
    "est(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83378861-dddf-4d4d-ae12-0ca16575d0a8",
   "metadata": {},
   "source": [
    "### Results\n",
    "For first dataset with _method = \"standard-support\"_ accuracy is 0.333\n",
    "\n",
    "For second dataset with _method = \"standard-support\"_ accuracy is 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a83ed4c-fc10-4994-9a07-203f77f5dce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_est(df):\n",
    "    acc = []\n",
    "    for i in range(0, 5):\n",
    "        te_rows = [k for k in range(3*i, 3*i + 3)]\n",
    "        test = df.iloc[te_rows]\n",
    "        train = df.drop(te_rows)\n",
    "        \n",
    "        y_train = train['Accgrade'] == 'T'\n",
    "        y_test = test['Accgrade'] == 'T'\n",
    "        X_train = train.drop('Accgrade', axis=1)\n",
    "        X_test = test.drop('Accgrade', axis=1)\n",
    "        \n",
    "        pat_cls = fcalc.classifier.PatternBinaryClassifier(X_train.values, y_train.to_numpy(), \n",
    "                                                       categorical=np.array([0, 1]), method = \"standard-support\")\n",
    "        pat_cls.predict(X_test.values)\n",
    "        acc.append(round(accuracy_score(y_test, pat_cls.predictions),4))\n",
    "        \n",
    "    print(\"res: \", acc)\n",
    "    return sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54145ab0-3b5f-47c9-b014-b3447b0f0c2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res:  [0.3333, 0.0, 0.3333, 0.3333, 0.0]\n",
      "0.19998\n"
     ]
    }
   ],
   "source": [
    "acc_df2 = cross_est(df2)\n",
    "print(acc_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e4d40-7c06-41be-9a52-c5fd8082096c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results with cross-validation on second dataset\n",
    "Here I have changed _IntervalPattern_ method in _patterns.py_ in such manner:\n",
    "> class IntervalPattern:\n",
    ">    def __init__(self, test, train) -> None:\n",
    ">        self.low = np.minimum(test, train)\n",
    ">        self.high = np.maximum(test, train)\n",
    "\n",
    "For stantard interval pattern\n",
    "\n",
    ">class IntervalPattern:\n",
    ">    def __init__(self, test, train) -> None:\n",
    ">        self.low = np.minimum(test, train)\n",
    "        self.high = np.full((self.low.size), 10**6)\n",
    "        \n",
    "For _(min, inf)_ interval pattern\n",
    "        \n",
    "        \n",
    ">class IntervalPattern:\n",
    "    def __init__(self, test, train) -> None:\n",
    "        self.low = np.maximum(test, train)\n",
    "        self.high = np.full((self.low.size), 10**6)\n",
    "        \n",
    "For _(max, inf)_interval pattern\n",
    "\n",
    "\n",
    "With stantard interval pattern accuracy is 0.66\n",
    "\n",
    "With _(min, inf)_ interval pattern accuracy is 0.73\n",
    "\n",
    "With _(max, inf)_ interval pattern accuracy is 0.19\n",
    "\n",
    "As we can see, _(min, inf)_ is more suitable. Such result happening in my opinion because such interval captures more data for review, resulting in improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848c8ac-9715-4728-b5b0-2a6406f74872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
